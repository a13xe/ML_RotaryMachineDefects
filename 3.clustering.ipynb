{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='lime'>\n",
    "\n",
    "# Clustering\n",
    "\n",
    "</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='yellow'>\n",
    "\n",
    "## 1. Model Training and Parameter Selection\n",
    "\n",
    "</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='orange'>\n",
    "\n",
    "### Import necessary libraries\n",
    "\n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='orange'>\n",
    "\n",
    "### Data preprocessing\n",
    "\n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/spotify_songs_cleaned.csv')\n",
    "\n",
    "# Selecting relevant features\n",
    "features = data[['track_popularity', 'danceability', 'energy', 'key', 'loudness',\n",
    "                 'mode', 'speechiness', 'acousticness', 'instrumentalness',\n",
    "                 'liveness', 'valence', 'tempo', 'duration_ms']]\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values in each column:\\n\", features.isnull().sum())\n",
    "\n",
    "# Normalize the features if not already normalized\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='orange'>\n",
    "\n",
    "### K-means Clustering\n",
    "\n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow method to find the optimal number of clusters (k)\n",
    "inertia = []\n",
    "for k in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(features_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plotting the Elbow Method Graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 11), inertia, marker='o')\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia') # how far the data points are from their cluster centers\n",
    "plt.show()\n",
    "\n",
    "# Choose the number of clusters based on the elbow method\n",
    "n_clusters_kmeans = 3\n",
    "kmeans = KMeans(n_clusters=n_clusters_kmeans, random_state=42)\n",
    "kmeans_clusters = kmeans.fit_predict(features_scaled)\n",
    "\n",
    "# Silhouette Score for K-means\n",
    "silhouette_avg_kmeans = silhouette_score(features_scaled, kmeans_clusters)\n",
    "print(\"K-means Silhouette Score: \", silhouette_avg_kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='orange'>\n",
    "\n",
    "### DBSCAN Clustering\n",
    "\n",
    "A way of grouping points (or data) so that similar points are in the same group and dissimilar points are in different groups\n",
    "\n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose eps and min_samples\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "dbscan_clusters = dbscan.fit_predict(features_scaled)\n",
    "\n",
    "# Silhouette Score for DBSCAN (if more than one cluster is formed)\n",
    "if len(set(dbscan_clusters)) > 1:\n",
    "    silhouette_avg_dbscan = silhouette_score(features_scaled, dbscan_clusters)\n",
    "    print(\"DBSCAN Silhouette Score: \", silhouette_avg_dbscan)\n",
    "else:\n",
    "    print(\"DBSCAN formed a single cluster or noise.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='orange'>\n",
    "\n",
    "### Hierarchical Clustering\n",
    "\n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import fcluster\n",
    "\n",
    "# Using the 'ward' linkage method # focuses on minimizing the sum of squared differences within all clusters\n",
    "linked = linkage(features_scaled, method='ward')\n",
    "plt.figure(figsize=(10, 7))\n",
    "dendrogram(linked, orientation='top', distance_sort='descending', show_leaf_counts=True)\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.show()\n",
    "\n",
    "# Choose the number of clusters based on the dendrogram\n",
    "n_clusters_hierarchical = 3\n",
    "hierarchical_clusters = fcluster(linked, n_clusters_hierarchical, criterion='maxclust')\n",
    "\n",
    "# Silhouette Score for Hierarchical Clustering\n",
    "silhouette_avg_hierarchical = silhouette_score(features_scaled, hierarchical_clusters)\n",
    "print(\"Hierarchical Clustering Silhouette Score: \", silhouette_avg_hierarchical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='yellow'>\n",
    "\n",
    "## 2. Visualization of predicted values\n",
    "\n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality Reduction for Visualization (using PCA)\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(features_scaled)\n",
    "\n",
    "# Plot the clusters for each method\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "# K-means clusters\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(principal_components[:, 0], principal_components[:, 1], c=kmeans_clusters, cmap='viridis')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('K-means Clustering')\n",
    "\n",
    "# DBSCAN clusters\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(principal_components[:, 0], principal_components[:, 1], c=dbscan_clusters, cmap='viridis')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('DBSCAN Clustering')\n",
    "\n",
    "# Hierarchical clusters\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(principal_components[:, 0], principal_components[:, 1], c=hierarchical_clusters, cmap='viridis')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('Hierarchical Clustering')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
